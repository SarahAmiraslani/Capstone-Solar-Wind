{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "It4EtySoHX2fYaJukvfJ3x",
     "type": "MD"
    }
   },
   "source": [
    "# In-Situ Data Dimensionality Reduction\n",
    "\n",
    "**Analytical Questions**\n",
    "\n",
    "- How can we apply novel dimension reduction methods, such as PCA, TSNE, etc., to obtain informative solar wind in-situ data representation in low-dimensional space? \n",
    "- How can this low-dimensional representation provide better 2D/3D visualization support than traditional dimension reduction techniques?\n",
    "\n",
    "\n",
    "For this project, we will explore 3 dimension reduction methods on the ACE Spacecraft In-situ Data:\n",
    "\n",
    "- **Principal Component Analysis (PCA)**: PCA is a technique that transforms the data into a new coordinate system such that the greatest variance by any projection of the data comes to lie on the first coordinate (called the first principal component), the second greatest variance on the second coordinate, and so on.\n",
    "  \n",
    "- **t-Distributed Stochastic Neighbor Embedding (t-SNE)**: t-SNE is a technique for dimensionality reduction that is particularly well suited for the visualization of high-dimensional datasets. It uses a probabilistic approach to model the similarity between points in high-dimensional and low-dimensional space.\n",
    "   \n",
    "- **Functional PCA (FPCA)**: This is the standard PCA process, but it emphasizes patterns of time series rather than absolute variance. This method can help visualize the variation of solar wind properties over time. \n",
    "  \n",
    "Each dimension reduction method was chosen for its ability to handle highly dimensional datasets. With the exception of PCA, each dimension reduction method can also handle non-linear data. Despite PCA's limited ability to handle non-linear data, we will apply Robust Scaler which applies a linear transformation of the data. \n",
    "\n",
    "**Min-max normalization vs. StandardScaler vs Robust Scaler**\n",
    "\n",
    "Min-max normalization is very sensitive to outliers and can compress our data. StandardScaler aggressively transforms the data by forcing normal distribution. From EDA we are aware that the data has a non-normal distribution and several features contain outliers.\n",
    "A robust scaler is resilient to outliers and maintains the original data's relationships similar to Min-Max normalization.\n",
    "\n",
    "The performance of each method will be assessed on _data visualization quality_. The data visualization quality reflects how well the reduced data captures the original data's patterns, clusters, and outliers. (e.g. scatter plots, heat maps, or silhouette plots).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "MAwMlB9d291KUmtTkRXySg",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Data Processing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Dimension Reduction Libraries\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import manifold\n",
    "from fdasrsf import fPCA, time_warping, fdawarp, fdahpca\n",
    "\n",
    "# Visualization Libraries\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "SpjVjyZ1hAOeIcKN0pijqm",
     "type": "MD"
    }
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "pnaIH1j5DqChqs0kzWdPiq",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/data/workspace_files/ACE_Data/2024-04-19_ace_master_clean_1hr.csv\", sep=\",\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "A7cOUKDIH8tdFmvoQ2aszy",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping Features we do not need in training data. Refer to notebook 02_EDA for more information.\n",
    "X = df.drop(\n",
    "    columns=[\n",
    "        \"Year\",\n",
    "        \"Day\",\n",
    "        \"Month\",\n",
    "        \"Seconds_OTD\",\n",
    "        \"gmt\",\n",
    "        \"timestamp\",\n",
    "        \"Anis_Index\",\n",
    "        \">30_MeV\",\n",
    "        \"Long\",\n",
    "        \"Lat\",\n",
    "        \"X\",\n",
    "        \"Y\",\n",
    "        \"Z\",\n",
    "    ]\n",
    ")\n",
    "Y = df[\"timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "47YcOBQtDcRsDq7QP7kRwl",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "#Feature Normalization\n",
    "scaler=RobustScaler()\n",
    "normalized_train = scaler.fit(X)\n",
    "\n",
    "print(\"number of features: {}\".format(normalized_train.n_features_in_))\n",
    "print(\"number of observations:{}\".format(X.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "ZBV9C9Ys8YSgPK18mYuV59",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "normalized_Xtrain = scaler.fit_transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "Nuj8vsYt6G5WzkuOaiANTV",
     "type": "MD"
    }
   },
   "source": [
    "## Creating low dimensional data spaces\n",
    "\n",
    "### 1. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "WSuhwk3bTNpFlMoMiQcQFc",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "\n",
    "pca = PCA()\n",
    "X_pca = pca.fit(normalized_Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "LiQbbCvwiwkMq9wzhyHzxj",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# determine the number of components are needed to describe the data\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel(\"number of components\")\n",
    "plt.ylabel(\"cumulative explained variance\")\n",
    "plt.title(\"Principal Component Analysis (PCA)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "ijrY63KEAZmGR6MeBD7G2J",
     "type": "MD"
    }
   },
   "source": [
    "The curve above quantifies how much of the variance is contained within the first N-components. The curve begins the level-out around 99% cumulative explained variance (5 components). This means we can reduce our data dimension to 5 from 15 without much loss of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "i0fZaTVd0f9iWPxpJc2Kgw",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Finding the top 3, most important features of each component\n",
    "num_components = 5\n",
    "pca = PCA(num_components)\n",
    "X_pca = pca.fit(normalized_Xtrain)\n",
    "\n",
    "# Putting results in dataframe\n",
    "pca_results = pd.DataFrame(pca.components_, columns=X.columns)\n",
    "\n",
    "pca_results[\"Component\"] = pca_results.index\n",
    "pca_results = pca_results.set_index(\"Component\")\n",
    "top3feat_df = pd.DataFrame(\n",
    "    pca_results.columns[np.argsort(-1 * pca_results.values, axis=1)[:, :3]],\n",
    "    columns=[\"1st\", \"2nd\", \" 3rd\"],\n",
    ")\n",
    "\n",
    "top3feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "DVsr6TEZaMVMlKGZpHZAyY",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "pca_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "dwbnNWWOba6ERVUI81SAz7",
     "type": "MD"
    }
   },
   "source": [
    "### 2. TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "bEK13Hqnsozyy9aRVR6E2x",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# T-Sne\n",
    "tsne = manifold.TSNE(n_components=3, init=\"pca\", random_state=42)\n",
    "X_tsne = tsne.fit_transform(normalized_Xtrain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "5dGdG53oR3tfZ6HI69gDuh",
     "type": "MD"
    }
   },
   "source": [
    "### 3. FPCA\n",
    "\n",
    "Using pipeline from [Medium](https://towardsdatascience.com/beyond-classic-pca-functional-principal-components-analysis-fpca-applied-to-time-series-with-python-914c058f47a0) article by Pierre-Louis Bescond "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "XTY3wFxfYPxmKI2qIgDZUI",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Data processing specifc to FPCA\n",
    "file_path = \"/data/workspace_files/ACE_Data/2024-04-19_ace_master_clean_1hr.csv\"\n",
    "df = pd.read_csv(file_path, sep=\",\")\n",
    "\n",
    "# Dropping Features we do not need in training data. Refer to notebook 02_EDA for more information.\n",
    "df = df.drop(\n",
    "    columns=[\n",
    "        \"Year\",\n",
    "        \"Day\",\n",
    "        \"Month\",\n",
    "        \"Seconds_OTD\",\n",
    "        \"gmt\",\n",
    "        \"Anis_Index\",\n",
    "        \">30_MeV\",\n",
    "        \"Long\",\n",
    "        \"Lat\",\n",
    "        \"X\",\n",
    "        \"Y\",\n",
    "        \"Z\",\n",
    "    ]\n",
    ")\n",
    "df = df.set_index(\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "iDnw9uFKn2UIOdn9J5sM2V",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Normalization\n",
    "scaler = RobustScaler()\n",
    "normalized_df = scaler.fit_transform(df)\n",
    "\n",
    "ace_df = pd.DataFrame(normalized_df, index=df.index, columns=df.columns)\n",
    "\n",
    "# Convert the Pandas dataframe to a Numpy array with time-series only\n",
    "f = ace_df[140000:].to_numpy().astype(float)\n",
    "\n",
    "# Create a float vector between 0 and 1 for time index\n",
    "time = np.linspace(0, 1, len(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "7sY5BkjXrAXGqsfFMYv0dz",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Align time-series\n",
    "warp_f = time_warping.fdawarp(f, time)\n",
    "warp_f.srsf_align()\n",
    "\n",
    "warp_f.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "qxPWQjikVIoZqYPGc2Wb7j",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Functional Principal Components Analysis\n",
    "\n",
    "# Define the FPCA as a vertical analysis\n",
    "fPCA_analysis = fPCA.fdavpca(warp_f)\n",
    "\n",
    "# Run the FPCA on a 5 components basis\n",
    "fPCA_analysis.calc_fpca(no=5)\n",
    "fPCA_analysis.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "MmPKC6ApkaJL6SrvGRKuuO",
     "type": "MD"
    }
   },
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "bj8s54v7KQZdke7V6apg7X",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# T-sne Visualization\n",
    "fig = px.scatter_3d(\n",
    "    X_tsne,\n",
    "    x=0,\n",
    "    y=1,\n",
    "    z=2,\n",
    ")\n",
    "fig.update_traces(marker_size=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "j4j296owdT34AmFWSmt99N",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# PCA Component Analysis\n",
    "pca = PCA()\n",
    "components = pca.fit_transform(normalized_Xtrain)\n",
    "labels = {\n",
    "    str(i): f\"PC {i+1} ({var:.1f}%)\"\n",
    "    for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n",
    "}\n",
    "\n",
    "fig = px.scatter_matrix(\n",
    "    components,\n",
    "    labels=labels,\n",
    "    dimensions=range(5),\n",
    ")\n",
    "fig.update_traces(diagonal_visible=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "kUp6WEtxWTmyN27jhmMqJX",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# PCA Component analysis Interactive\n",
    "app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div(\n",
    "    [\n",
    "        html.H4(\"Visualization of PCA's explained variance\"),\n",
    "        dcc.Graph(id=\"graph\"),\n",
    "        html.P(\"Number of components:\"),\n",
    "        dcc.Slider(id=\"slider\", min=2, max=15, value=3, step=1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "@app.callback(Output(\"graph\", \"figure\"), Input(\"slider\", \"value\"))\n",
    "def run_and_plot(n_components):\n",
    "    # replace with your own data source\n",
    "    df = normalized_Xtrain\n",
    "    pca = PCA(n_components=n_components)\n",
    "    components = pca.fit_transform(df)\n",
    "\n",
    "    var = pca.explained_variance_ratio_.sum() * 100\n",
    "\n",
    "    labels = {str(i): f\"PC {i+1}\" for i in range(n_components)}\n",
    "\n",
    "    fig = px.scatter_matrix(\n",
    "        components,\n",
    "        dimensions=range(n_components),\n",
    "        labels=labels,\n",
    "        title=f\"Total Explained Variance: {var:.2f}%\",\n",
    "    )\n",
    "    fig.update_traces(diagonal_visible=False)\n",
    "    return fig\n",
    "\n",
    "\n",
    "app.run_server(debug=False, host=\"0.0.0.0\", port=8890)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "lhXJb28pCqJUVo7mzSZSaa",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# FPCA Visualization\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Plot of the 5 functions\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Scatter(y=fPCA_analysis.f_pca[:, 0, 0], mode=\"lines\", name=\"PC1\"))\n",
    "fig.add_trace(go.Scatter(y=fPCA_analysis.f_pca[:, 0, 1], mode=\"lines\", name=\"PC2\"))\n",
    "fig.add_trace(go.Scatter(y=fPCA_analysis.f_pca[:, 0, 2], mode=\"lines\", name=\"PC3\"))\n",
    "fig.add_trace(go.Scatter(y=fPCA_analysis.f_pca[:, 0, 3], mode=\"lines\", name=\"PC4\"))\n",
    "fig.add_trace(go.Scatter(y=fPCA_analysis.f_pca[:, 0, 4], mode=\"lines\", name=\"PC5\"))\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"<b>Principal Components Analysis Functions of Jan. 2019 - Apr. 2024 Solar Wind Insitu Measurements Data</b>\",\n",
    "    title_x=0.5,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [
    {
     "name": "dash",
     "source": "PIP",
     "version": "2.16.1"
    },
    {
     "name": "fdasrsf",
     "source": "PIP",
     "version": "2.5.10"
    }
   ],
   "report_row_ids": [],
   "version": 3
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
